{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    augmented_images = []\n",
    "    augmented_images.append(image)\n",
    "    augmented_images.append(tf.image.flip_left_right(image))\n",
    "    augmented_images.append(tf.image.rot90(image))\n",
    "    augmented_images.append(tf.image.flip_up_down(image))\n",
    "    \n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_extract_features(images, labels):\n",
    "    sift = cv2.SIFT_create()\n",
    "    descriptors = []\n",
    "    descriptor_labels = []\n",
    "    \n",
    "    for img, label in zip(images, labels):\n",
    "        try:\n",
    "            if isinstance(img, tf.Tensor):\n",
    "                img = img.numpy()\n",
    "            resized_img = cv2.resize(img, (224, 224))\n",
    "            \n",
    "            if np.max(resized_img) <= 1.0:\n",
    "                resized_img = (resized_img * 255).astype(np.uint8)\n",
    "            else:\n",
    "                resized_img = resized_img.astype(np.uint8)\n",
    "            keypoints, desc = sift.detectAndCompute(resized_img, None)\n",
    "            \n",
    "            if desc is not None and len(desc) > 0:\n",
    "                descriptors.append(desc)\n",
    "                descriptor_labels.append(label)\n",
    "            else:\n",
    "                print(f\"No descriptors found for label {label}. Skipping this image.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image with label {label}: {e}\")\n",
    "    \n",
    "    if len(descriptors) == 0:\n",
    "        raise ValueError(\"No valid descriptors found in the dataset.\")\n",
    "    \n",
    "    combined_descriptors = np.vstack(descriptors)\n",
    "    combined_labels = np.hstack([[label] * len(desc) for label, desc in zip(descriptor_labels, descriptors)])\n",
    "    \n",
    "    return combined_descriptors, combined_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_path = \"./batik_assets/\"\n",
    "images = []\n",
    "class_list = []\n",
    "label_class = ['batik-bali', 'batik-betawi', 'batik-celup', 'batik-cendrawasih', 'batik-ceplok', 'batik-ciamis', 'batik-garutan', 'batik-gentongan', 'batik-kawung', 'batik-keraton', 'batik-lasem', 'batik-megamendung', 'batik-parang', 'batik-pekalongan', 'batik-priangan', 'batik-sekar', 'batik-sidoluhur', 'batik-sidomukti', 'batik-sogan', 'batik-tambal']\n",
    "class_images = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, class_name in enumerate(label_class):\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for file in os.listdir(class_path):\n",
    "            try:\n",
    "                file_path = os.path.join(class_path, file)\n",
    "                image = load_img(file_path)\n",
    "                image = img_to_array(image)\n",
    "                image = tf.image.resize(image, (256, 256)) / 255.0\n",
    "                class_images[class_name].append((image, i))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for class_name, images_and_labels in class_images.items():\n",
    "    for img, label in images_and_labels:\n",
    "        all_images.append(img.numpy())\n",
    "        all_labels.append(label)\n",
    "\n",
    "all_images = np.array(all_images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    all_images, all_labels, test_size=0.2, stratify=all_labels,random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_images = []\n",
    "augmented_train_labels = []\n",
    "\n",
    "for img, label in zip(train_images, train_labels):\n",
    "    augmented_images = augment_image(tf.convert_to_tensor(img))\n",
    "    for aug_image in augmented_images:\n",
    "        augmented_train_images.append(aug_image.numpy())\n",
    "        augmented_train_labels.append(label)\n",
    "\n",
    "augmented_train_images = np.array(augmented_train_images)\n",
    "augmented_train_labels = np.array(augmented_train_labels)\n",
    "\n",
    "descriptors_train, labels_train = preprocess_and_extract_features(augmented_train_images, augmented_train_labels)\n",
    "descriptors_test, labels_test = preprocess_and_extract_features(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.08      0.09      8570\n",
      "           1       0.16      0.13      0.14      8507\n",
      "           2       0.06      0.05      0.05      4366\n",
      "           3       0.06      0.05      0.06      4382\n",
      "           4       0.15      0.16      0.16      5913\n",
      "           5       0.25      0.32      0.28      6997\n",
      "           6       0.10      0.08      0.09      7105\n",
      "           7       0.06      0.05      0.06      7189\n",
      "           8       0.18      0.17      0.18      5405\n",
      "           9       0.07      0.08      0.08      8796\n",
      "          10       0.14      0.13      0.13     10528\n",
      "          11       0.47      0.45      0.46      6742\n",
      "          12       0.25      0.40      0.31      6605\n",
      "          13       0.13      0.10      0.11      8441\n",
      "          14       0.03      0.03      0.03      7001\n",
      "          15       0.08      0.07      0.07      3489\n",
      "          16       0.17      0.34      0.23      5031\n",
      "          17       0.10      0.07      0.08      6774\n",
      "          18       0.03      0.02      0.02      3232\n",
      "          19       0.14      0.14      0.14      6522\n",
      "\n",
      "    accuracy                           0.15    131595\n",
      "   macro avg       0.14      0.15      0.14    131595\n",
      "weighted avg       0.14      0.15      0.14    131595\n",
      "\n",
      "KNN Accuracy: 0.14853147915954254\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(descriptors_train, labels_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(descriptors_test)\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(labels_test, y_pred_knn))\n",
    "print(\"KNN Accuracy:\", accuracy_score(labels_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "knnPickle = open('knn_model.pkl', 'wb')\n",
    "pickle.dump(knn_model, knnPickle)\n",
    "knnPickle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
